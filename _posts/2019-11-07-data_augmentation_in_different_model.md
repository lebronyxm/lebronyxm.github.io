---
layout:     post
title:      ctr模型和相关性模型里的数据增强(样本采样、加权、构造)
subtitle:   从线上系统探讨正负样本对模型的影响
date:       2019-11-07
author:     Yang xuemeng
header-img: img/post-bg-re-vs-ng2.jpg
catalog: true
tags:
    - 模型算法
    - 数学理论
---

## 前言

直奔主题。基本每个人都知道样本平衡的问题。以2分类模型为例,在很多场景下都存在正负样本不均衡的情况，比如欺诈检测、ctr、cvr等等。这类任务基本都会面临训练样本分布和预测数据分布不一致的问题。当然有很多的方法来缓解这个问题，比如联合训练等。本文想记录下，对两种任务模型中，正负样本比例对模型的的影响。

### ctr等业务模型
1.任务不同，作用不同。相关性类的，是客观的label（不考虑人工主观评估）。而ctr类的则是比较复杂的，展示了未点击的不一定不好。

2.ctr里，有展现的负样本，这部分数据性质很特殊，不代表这个user，flow，ad的质量不好；同时点击高了，还要考虑cpm等因素，不能过于打压高acp的ad；再者，还要考虑用户体验，需要打压集中性，以及隐私问题;如果模型模板是cpm或者ctr之类的，那么给一个user、flow推出来的ann结果就是相近的ctr或者cpm的ad。多样性不好把控，相关性也不好把控。这些ann的结果，不一定互相间有联系。这点和相关性任务不同。。。

3.对有展现的负样本采样，有用

4.构造对没有展现的负样本，有用。随机构造，按照ad的pv来构造，影响不一样。

5.构造正样本，这里更像是data augmentation。有用。

6.总体感觉，就是尽量让模型，见到更多的候选集。负样本，不同分布位置的负样本，对模型作用不同。

7.所谓的biased prediction, google 13年的FTRL里用的这个采样后加权的思路，理论上没问题。可是实际使用中，我们采样了负样本后，并没有对负样本加权，也没啥问题。

8.去掉一些低质流量数据(负样本太多，比正常流量上多，是的一些组合变成不合理的负例？)和异常流量下的数据，相当于去噪，和样本比例矫正。有用。

### 图文相关性问题
1.该增加尽可能多图或文，即使这个文只有一个pair。提高泛化。

2.还是该对同一个文或图，增加其丰富的pair，是的这个文图学习的更充分。提高准确度。

3.应用到了transfer learning，如果预训练的embedding是具有泛化能力的语义向量，即知道火车和飞机都是旅游工具。那么在其他任务比如图文相关性任务重，正样本只有火车-旅游，训练出的模型也应该能保留\学到飞机-旅游也是正例。

## 数学角度分析
上面讨论的ctr和相关性2个任务，由于场景不同，在优化样本时，也会有一些不同的思路和角度。但是样本对于模型的影响，在数值算法上来说，应该是一样的。这里想讨论下在batch-SGD的算法下，样本重采样、下采样+加权、epoch重复，这几个的联系与区别。
